{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvoluční sítě pro klasifikaci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Úkolem cvičení je upravit tento notebook a dosáhnout co nejlepšího možného validačního skóre na datasetu CIFAR-10. Viz nápovědu a možné směry úprav v komentářích u jednotlivých buněk. Klasifikaci obrázků pomocí konvolučních sítí v PyTorch popisuje notebook [pytorch-convnets](lectures/pytorch-convnets.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zlepsi predzpracovani a jine augmentace skore?\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=train_transform)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentaci lze provadet i v testovacim rezimu\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=valid_transform)\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pomuze jina batch_size?\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kritérium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# muze zlepsit skore napr. SVM?\n",
    "crit = nn.CrossEntropyLoss()\n",
    "crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definice konvoluční sítě"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Síť definujte následující třídou `Convnet`. Není povoleno používat modely z `torchvision.models` ať už předtrénovanou či nepředtrénovanou verzi, ani jinou formu transfer learningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, 5, 1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.Conv2d(192, 160, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(160),\n",
    "                nn.Conv2d(160,  96, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(96),\n",
    "                nn.MaxPool2d(3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Conv2d(96, 192, 5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.Conv2d(192, 192, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.Conv2d(192, 192, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.AvgPool2d(3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Conv2d(192, 192, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.Conv2d(192, 192, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(192),\n",
    "                nn.Conv2d(192, 10, 1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(8, stride=1, padding=0),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(x.size(0), 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trénování a validace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pokud vytvorime novou sit, vyresetujeme i statistiky\n",
    "model = Convnet()\n",
    "stats = ans.Stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convnet(\n",
       "  (classifier): Sequential(\n",
       "    (0): Conv2d(3, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "    (21): Dropout(p=0.5, inplace=False)\n",
       "    (22): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (28): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.0.weight torch.float32 torch.Size([192, 3, 5, 5]) 14400\n",
      "classifier.0.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.2.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.2.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.3.weight torch.float32 torch.Size([160, 192, 1, 1]) 30720\n",
      "classifier.3.bias torch.float32 torch.Size([160]) 160\n",
      "classifier.5.weight torch.float32 torch.Size([160]) 160\n",
      "classifier.5.bias torch.float32 torch.Size([160]) 160\n",
      "classifier.6.weight torch.float32 torch.Size([96, 160, 1, 1]) 15360\n",
      "classifier.6.bias torch.float32 torch.Size([96]) 96\n",
      "classifier.8.weight torch.float32 torch.Size([96]) 96\n",
      "classifier.8.bias torch.float32 torch.Size([96]) 96\n",
      "classifier.11.weight torch.float32 torch.Size([192, 96, 5, 5]) 460800\n",
      "classifier.11.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.13.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.13.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.14.weight torch.float32 torch.Size([192, 192, 1, 1]) 36864\n",
      "classifier.14.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.16.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.16.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.17.weight torch.float32 torch.Size([192, 192, 1, 1]) 36864\n",
      "classifier.17.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.19.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.19.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.22.weight torch.float32 torch.Size([192, 192, 3, 3]) 331776\n",
      "classifier.22.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.24.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.24.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.25.weight torch.float32 torch.Size([192, 192, 1, 1]) 36864\n",
      "classifier.25.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.27.weight torch.float32 torch.Size([192]) 192\n",
      "classifier.27.bias torch.float32 torch.Size([192]) 192\n",
      "classifier.28.weight torch.float32 torch.Size([10, 192, 1, 1]) 1920\n",
      "classifier.28.bias torch.float32 torch.Size([10]) 10\n"
     ]
    }
   ],
   "source": [
    "for name, par in model.named_parameters():\n",
    "    print(name, par.dtype, par.shape, par.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s novou siti musime obnovit i seznam parametru pro optimizer\n",
    "# lepsich vysledku obvykle dosahuje SGD s momentum\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nasledujici kod libovolne upravujte\n",
    "\n",
    "def train_step(model, batch, crit, optimizer, stats):\n",
    "    # prepnout model do trenovaciho rezimu (tyka se vrstev jako Dropout nebo BatchNorm2d)\n",
    "    model.train()\n",
    "    \n",
    "    # zajistit, aby model i data byla na stejnem zarizeni (cpu vs gpu)\n",
    "    device = next(model.parameters()).device\n",
    "    inputs, targets = batch\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    # dopredny pruchod\n",
    "    scores = model(inputs)\n",
    "\n",
    "    # loss\n",
    "    loss = crit(scores, targets)\n",
    "\n",
    "    # pred zpetnym pruchodem vycistit prip. existujici gradienty z minulych iteraci\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # zpetny pruchod, gradienty se ulozi primo do parametru modelu do atributu `grad`\n",
    "    loss.backward()\n",
    "\n",
    "    # update parametru na zaklade atributu `grad`\n",
    "    optimizer.step()\n",
    "\n",
    "    # vyhodnotime presnost\n",
    "    _, pred = scores.max(dim=1)\n",
    "    acc = torch.sum(pred == targets).float() / targets.shape[0]\n",
    "    \n",
    "    # update aktualnich statistik\n",
    "    stats.append_batch_stats('train', loss=float(loss), acc=float(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3590bd33ad44aeb8e4ceb140080f8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 01 train:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-c77bcd2962d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'epoch {:02d} train'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         pb.set_postfix(\n\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'{:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-ce1f285c223b>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(model, batch, crit, optimizer, stats)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# update aktualnich statistik\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_batch_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# jaky vliv ma pocet epoch?\n",
    "# zkuste postupne menit learning rate (optimizer.param_groups[0]['lr'] = ...)\n",
    "# nebo pomoci scheduleru (https://pytorch.org/docs/master/optim.html#how-to-adjust-learning-rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95], gamma=0.01)\n",
    "\n",
    "for ep in range(100):\n",
    "    stats.new_epoch()\n",
    "    \n",
    "    # trenovaci faze\n",
    "    pb = tqdm.auto.tqdm(train_loader, desc='epoch {:02d} train'.format(ep+1))\n",
    "    for inputs, targets in pb:\n",
    "        train_step(model, (inputs, targets), crit, optimizer, stats)\n",
    "        pb.set_postfix(\n",
    "            loss='{:.3f}'.format(stats.ravg('train', 'loss')),\n",
    "            acc='{:.3f}'.format(stats.ravg('train', 'acc'))\n",
    "        )\n",
    "    scheduler.step()\n",
    "    \n",
    "    # validacni faze\n",
    "    ans.validate(model, crit, valid_loader, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot_by_batch(block_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.plot_by_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Epoch 05</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.511154</td>\n",
       "      <td>0.826027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.524774</td>\n",
       "      <td>0.818471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Epoch 05      loss       acc\n",
       "train     0.511154  0.826027\n",
       "valid     0.524774  0.818471"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.best_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikce na testovacím obrázku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), (500, 500, 3), 0, 252)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_test = cv2.imread('./data/happy-green-frog.jpg')[..., ::-1]\n",
    "rgb_test.dtype, rgb_test.shape, rgb_test.min(), rgb_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.predict_and_show(cv2.resize(rgb_test, (32, 32)), model, valid_transform, classes=train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
